{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82f53314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (2.1.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (0.16.1+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (2.1.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (from torchvision) (1.24.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (from requests->torchvision) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hp\\anaconda3\\envs\\mcunetv3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e83fa84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package            Version\n",
      "------------------ ------------\n",
      "certifi            2022.12.7\n",
      "charset-normalizer 2.1.1\n",
      "filelock           3.9.0\n",
      "fsspec             2023.4.0\n",
      "idna               3.4\n",
      "Jinja2             3.1.2\n",
      "MarkupSafe         2.1.3\n",
      "mpmath             1.3.0\n",
      "networkx           3.0\n",
      "numpy              1.24.1\n",
      "Pillow             9.3.0\n",
      "pip                23.3\n",
      "requests           2.28.1\n",
      "setuptools         68.0.0\n",
      "sympy              1.12\n",
      "torch              2.1.1+cu118\n",
      "torchaudio         2.1.1+cu118\n",
      "torchvision        0.16.1+cu118\n",
      "typing_extensions  4.4.0\n",
      "urllib3            1.26.13\n",
      "wheel              0.41.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02e49ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a1e041-55a1-42cf-844d-8ac050fdc361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision.models import mobilenet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eda48f6-5ed9-4355-ba34-2752e550af2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 转换器\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 加载训练集和测试集\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf7685f-e582-41d8-8de9-f3db75a5d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加标签噪声的函数\n",
    "def add_label_noise(labels, noise_type='symmetric', noise_rate=0.2):\n",
    "    noisy_labels = labels.copy()\n",
    "    n_samples = labels.shape[0]\n",
    "    n_classes = 10\n",
    "\n",
    "    if noise_type == 'symmetric':\n",
    "        n_noisy = int(noise_rate * n_samples)\n",
    "        noise_idx = np.random.choice(n_samples, n_noisy, replace=False)\n",
    "        for idx in noise_idx:\n",
    "            original_label = labels[idx]\n",
    "            noisy_labels[idx] = np.random.choice([l for l in range(n_classes) if l != original_label])\n",
    "    elif noise_type == 'pairflip':\n",
    "        for i in range(n_classes // 2):\n",
    "            flip_from = i * 2\n",
    "            flip_to = flip_from + 1\n",
    "            flip_idx = np.where(labels == flip_from)[0]\n",
    "            n_flip = int(noise_rate * len(flip_idx))\n",
    "            flip_idx = np.random.choice(flip_idx, n_flip, replace=False)\n",
    "            noisy_labels[flip_idx] = flip_to\n",
    "\n",
    "    return noisy_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6af19ee0-d999-4bc6-a9bf-644eec3449ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e91ac042-72eb-4fb1-85db-88e966d38baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Epoch: 1, Batch: 200/782, Loss: 2.364282908439636\n",
      "Epoch: 1, Batch: 400/782, Loss: 2.31845291018486\n",
      "Epoch: 1, Batch: 600/782, Loss: 2.2762377667427063\n",
      "Epoch 1 loss: 0.5281820876519089\n",
      "Epoch: 2, Batch: 200/782, Loss: 2.2485444927215577\n",
      "Epoch: 2, Batch: 400/782, Loss: 2.2461135244369506\n",
      "Epoch: 2, Batch: 600/782, Loss: 2.2340430134534834\n",
      "Epoch 2 loss: 0.5137156909688965\n",
      "Epoch: 3, Batch: 200/782, Loss: 2.206979848742485\n",
      "Epoch: 3, Batch: 400/782, Loss: 2.1875879365205764\n",
      "Epoch: 3, Batch: 600/782, Loss: 2.182610951066017\n",
      "Epoch 3 loss: 0.5060442614433406\n",
      "Epoch: 4, Batch: 200/782, Loss: 2.164680314064026\n",
      "Epoch: 4, Batch: 400/782, Loss: 2.1573827505111693\n",
      "Epoch: 4, Batch: 600/782, Loss: 2.1491634953022003\n",
      "Epoch 4 loss: 0.4990552788805169\n",
      "Epoch: 5, Batch: 200/782, Loss: 2.1254815834760667\n",
      "Epoch: 5, Batch: 400/782, Loss: 2.118248967528343\n",
      "Epoch: 5, Batch: 600/782, Loss: 2.114011978507042\n",
      "Epoch 5 loss: 0.4932973499188338\n",
      "Epoch: 6, Batch: 200/782, Loss: 2.109225798845291\n",
      "Epoch: 6, Batch: 400/782, Loss: 2.1000572514533995\n",
      "Epoch: 6, Batch: 600/782, Loss: 2.1033369010686873\n",
      "Epoch 6 loss: 0.48845692988856676\n",
      "Epoch: 7, Batch: 200/782, Loss: 2.0996894317865373\n",
      "Epoch: 7, Batch: 400/782, Loss: 2.0867312985658644\n",
      "Epoch: 7, Batch: 600/782, Loss: 2.0838058584928514\n",
      "Epoch 7 loss: 0.4831424326543003\n",
      "Epoch: 8, Batch: 200/782, Loss: 2.075492238998413\n",
      "Epoch: 8, Batch: 400/782, Loss: 2.0559809011220933\n",
      "Epoch: 8, Batch: 600/782, Loss: 2.053771783709526\n",
      "Epoch 8 loss: 0.47948187482936305\n",
      "Epoch: 9, Batch: 200/782, Loss: 2.0362412548065185\n",
      "Epoch: 9, Batch: 400/782, Loss: 2.0498725140094756\n",
      "Epoch: 9, Batch: 600/782, Loss: 2.03012297809124\n",
      "Epoch 9 loss: 0.4730748209502081\n",
      "Epoch: 10, Batch: 200/782, Loss: 2.0250929188728333\n",
      "Epoch: 10, Batch: 400/782, Loss: 2.0263156443834305\n",
      "Epoch: 10, Batch: 600/782, Loss: 2.014628984928131\n",
      "Epoch 10 loss: 0.4715369322415813\n",
      "Epoch: 11, Batch: 200/782, Loss: 2.010791839361191\n",
      "Epoch: 11, Batch: 400/782, Loss: 2.007851445674896\n",
      "Epoch: 11, Batch: 600/782, Loss: 2.0048183923959733\n",
      "Epoch 11 loss: 0.4685318183411113\n",
      "Epoch: 12, Batch: 200/782, Loss: 1.9902164292335511\n",
      "Epoch: 12, Batch: 400/782, Loss: 2.0018558782339095\n",
      "Epoch: 12, Batch: 600/782, Loss: 1.9999067878723145\n",
      "Epoch 12 loss: 0.4659956228702574\n",
      "Epoch: 13, Batch: 200/782, Loss: 1.992058140039444\n",
      "Epoch: 13, Batch: 400/782, Loss: 1.9872535967826843\n",
      "Epoch: 13, Batch: 600/782, Loss: 1.9803480094671249\n",
      "Epoch 13 loss: 0.4614132270788598\n",
      "Epoch: 14, Batch: 200/782, Loss: 1.973381029367447\n",
      "Epoch: 14, Batch: 400/782, Loss: 1.9760749351978302\n",
      "Epoch: 14, Batch: 600/782, Loss: 1.976998980641365\n",
      "Epoch 14 loss: 0.4619347535435806\n",
      "Epoch: 15, Batch: 200/782, Loss: 1.955818138718605\n",
      "Epoch: 15, Batch: 400/782, Loss: 1.9777408921718598\n",
      "Epoch: 15, Batch: 600/782, Loss: 1.9541637980937958\n",
      "Epoch 15 loss: 0.45715925836807014\n",
      "Epoch: 16, Batch: 200/782, Loss: 1.9589659094810485\n",
      "Epoch: 16, Batch: 400/782, Loss: 1.9541894483566284\n",
      "Epoch: 16, Batch: 600/782, Loss: 1.9634942311048507\n",
      "Epoch 16 loss: 0.4553752264098438\n",
      "Epoch: 17, Batch: 200/782, Loss: 1.9376005375385283\n",
      "Epoch: 17, Batch: 400/782, Loss: 1.9491025358438492\n",
      "Epoch: 17, Batch: 600/782, Loss: 1.9430921906232834\n",
      "Epoch 17 loss: 0.4538077571812798\n",
      "Epoch: 18, Batch: 200/782, Loss: 1.931214359998703\n",
      "Epoch: 18, Batch: 400/782, Loss: 1.931939896941185\n",
      "Epoch: 18, Batch: 600/782, Loss: 1.9417242759466171\n",
      "Epoch 18 loss: 0.4507602761163736\n",
      "Epoch: 19, Batch: 200/782, Loss: 1.92762335896492\n",
      "Epoch: 19, Batch: 400/782, Loss: 1.9398752909898758\n",
      "Epoch: 19, Batch: 600/782, Loss: 1.9392725557088852\n",
      "Epoch 19 loss: 0.4492019472829521\n",
      "Epoch: 20, Batch: 200/782, Loss: 1.9132068699598312\n",
      "Epoch: 20, Batch: 400/782, Loss: 1.9231226933002472\n",
      "Epoch: 20, Batch: 600/782, Loss: 1.9268272840976715\n",
      "Epoch 20 loss: 0.44765389544884565\n",
      "Epoch: 21, Batch: 200/782, Loss: 1.9126065558195113\n",
      "Epoch: 21, Batch: 400/782, Loss: 1.9084968250989913\n",
      "Epoch: 21, Batch: 600/782, Loss: 1.9192488998174668\n",
      "Epoch 21 loss: 0.44516591495260255\n",
      "Epoch: 22, Batch: 200/782, Loss: 1.9053382897377014\n",
      "Epoch: 22, Batch: 400/782, Loss: 1.9067674326896666\n",
      "Epoch: 22, Batch: 600/782, Loss: 1.9138067400455474\n",
      "Epoch 22 loss: 0.445992704090255\n",
      "Epoch: 23, Batch: 200/782, Loss: 1.8985780584812164\n",
      "Epoch: 23, Batch: 400/782, Loss: 1.8959730750322341\n",
      "Epoch: 23, Batch: 600/782, Loss: 1.9088242942094802\n",
      "Epoch 23 loss: 0.44549166378767596\n",
      "Epoch: 24, Batch: 200/782, Loss: 1.9032857018709182\n",
      "Epoch: 24, Batch: 400/782, Loss: 1.898058741092682\n",
      "Epoch: 24, Batch: 600/782, Loss: 1.9074055010080337\n",
      "Epoch 24 loss: 0.44111410644658083\n",
      "Epoch: 25, Batch: 200/782, Loss: 1.8840395355224608\n",
      "Epoch: 25, Batch: 400/782, Loss: 1.8938150292634963\n",
      "Epoch: 25, Batch: 600/782, Loss: 1.8889303040504455\n",
      "Epoch 25 loss: 0.4403846622123133\n",
      "Epoch: 26, Batch: 200/782, Loss: 1.8869956630468367\n",
      "Epoch: 26, Batch: 400/782, Loss: 1.8777000546455382\n",
      "Epoch: 26, Batch: 600/782, Loss: 1.8827054518461228\n",
      "Epoch 26 loss: 0.43885949353122955\n",
      "Epoch: 27, Batch: 200/782, Loss: 1.8790925008058548\n",
      "Epoch: 27, Batch: 400/782, Loss: 1.8837750786542893\n",
      "Epoch: 27, Batch: 600/782, Loss: 1.8760595089197158\n",
      "Epoch 27 loss: 0.4373157054871854\n",
      "Epoch: 28, Batch: 200/782, Loss: 1.8655379581451417\n",
      "Epoch: 28, Batch: 400/782, Loss: 1.8765686631202698\n",
      "Epoch: 28, Batch: 600/782, Loss: 1.8806514716148377\n",
      "Epoch 28 loss: 0.4369676021663734\n",
      "Epoch: 29, Batch: 200/782, Loss: 1.8614053028821944\n",
      "Epoch: 29, Batch: 400/782, Loss: 1.8645748615264892\n",
      "Epoch: 29, Batch: 600/782, Loss: 1.8636031746864319\n",
      "Epoch 29 loss: 0.4337199071179266\n",
      "Epoch: 30, Batch: 200/782, Loss: 1.8631808823347091\n",
      "Epoch: 30, Batch: 400/782, Loss: 1.868084579706192\n",
      "Epoch: 30, Batch: 600/782, Loss: 1.8657952332496643\n",
      "Epoch 30 loss: 0.43497886956500276\n",
      "Epoch: 31, Batch: 200/782, Loss: 1.8588416212797165\n",
      "Epoch: 31, Batch: 400/782, Loss: 1.8550801879167558\n",
      "Epoch: 31, Batch: 600/782, Loss: 1.8577688187360764\n",
      "Epoch 31 loss: 0.4310225313886657\n",
      "Epoch: 32, Batch: 200/782, Loss: 1.846486080288887\n",
      "Epoch: 32, Batch: 400/782, Loss: 1.859115305542946\n",
      "Epoch: 32, Batch: 600/782, Loss: 1.8548424422740937\n",
      "Epoch 32 loss: 0.43482182291157717\n",
      "Epoch: 33, Batch: 200/782, Loss: 1.8390495651960372\n",
      "Epoch: 33, Batch: 400/782, Loss: 1.8500799852609635\n",
      "Epoch: 33, Batch: 600/782, Loss: 1.862079024910927\n",
      "Epoch 33 loss: 0.43222391559644735\n",
      "Epoch: 34, Batch: 200/782, Loss: 1.8607371532917023\n",
      "Epoch: 34, Batch: 400/782, Loss: 1.8421857553720473\n",
      "Epoch: 34, Batch: 600/782, Loss: 1.8450489521026612\n",
      "Epoch 34 loss: 0.42840912046334934\n",
      "Epoch: 35, Batch: 200/782, Loss: 1.8429397821426392\n",
      "Epoch: 35, Batch: 400/782, Loss: 1.8393485724925995\n",
      "Epoch: 35, Batch: 600/782, Loss: 1.8371050786972045\n",
      "Epoch 35 loss: 0.4301511474582545\n",
      "Epoch: 36, Batch: 200/782, Loss: 1.8294685280323029\n",
      "Epoch: 36, Batch: 400/782, Loss: 1.8424014735221863\n",
      "Epoch: 36, Batch: 600/782, Loss: 1.8404508405923843\n",
      "Epoch 36 loss: 0.4305333072876991\n",
      "Epoch: 37, Batch: 200/782, Loss: 1.830607333779335\n",
      "Epoch: 37, Batch: 400/782, Loss: 1.8322040683031082\n",
      "Epoch: 37, Batch: 600/782, Loss: 1.8366702383756637\n",
      "Epoch 37 loss: 0.42642665107536804\n",
      "Epoch: 38, Batch: 200/782, Loss: 1.8119832372665405\n",
      "Epoch: 38, Batch: 400/782, Loss: 1.823863341808319\n",
      "Epoch: 38, Batch: 600/782, Loss: 1.8317926520109176\n",
      "Epoch 38 loss: 0.4278183484931126\n",
      "Epoch: 39, Batch: 200/782, Loss: 1.820097359418869\n",
      "Epoch: 39, Batch: 400/782, Loss: 1.8223429840803147\n",
      "Epoch: 39, Batch: 600/782, Loss: 1.822424283027649\n",
      "Epoch 39 loss: 0.4280214212129793\n",
      "Epoch: 40, Batch: 200/782, Loss: 1.8157348066568375\n",
      "Epoch: 40, Batch: 400/782, Loss: 1.8024623250961305\n",
      "Epoch: 40, Batch: 600/782, Loss: 1.8183124220371247\n",
      "Epoch 40 loss: 0.4224204980503872\n",
      "Epoch: 41, Batch: 200/782, Loss: 1.8159926056861877\n",
      "Epoch: 41, Batch: 400/782, Loss: 1.8206425166130067\n",
      "Epoch: 41, Batch: 600/782, Loss: 1.810995026230812\n",
      "Epoch 41 loss: 0.42339159460628734\n",
      "Epoch: 42, Batch: 200/782, Loss: 1.8009446477890014\n",
      "Epoch: 42, Batch: 400/782, Loss: 1.812042554616928\n",
      "Epoch: 42, Batch: 600/782, Loss: 1.8179743683338165\n",
      "Epoch 42 loss: 0.4233528006717067\n",
      "Epoch: 43, Batch: 200/782, Loss: 1.8066072314977646\n",
      "Epoch: 43, Batch: 400/782, Loss: 1.8187042152881623\n",
      "Epoch: 43, Batch: 600/782, Loss: 1.7982236063480377\n",
      "Epoch 43 loss: 0.4226482217878942\n",
      "Epoch: 44, Batch: 200/782, Loss: 1.7975225734710694\n",
      "Epoch: 44, Batch: 400/782, Loss: 1.8046064138412476\n",
      "Epoch: 44, Batch: 600/782, Loss: 1.8068258714675904\n",
      "Epoch 44 loss: 0.4243601953891842\n",
      "Epoch: 45, Batch: 200/782, Loss: 1.835518290400505\n",
      "Epoch: 45, Batch: 400/782, Loss: 1.8141471070051194\n",
      "Epoch: 45, Batch: 600/782, Loss: 1.8068162995576857\n",
      "Epoch 45 loss: 0.4241460227905332\n",
      "Epoch: 46, Batch: 200/782, Loss: 1.7880039262771605\n",
      "Epoch: 46, Batch: 400/782, Loss: 1.7998724031448363\n",
      "Epoch: 46, Batch: 600/782, Loss: 1.8081446009874345\n",
      "Epoch 46 loss: 0.42101285326511356\n",
      "Epoch: 47, Batch: 200/782, Loss: 1.7935665541887282\n",
      "Epoch: 47, Batch: 400/782, Loss: 1.7948035061359406\n",
      "Epoch: 47, Batch: 600/782, Loss: 1.8001214957237244\n",
      "Epoch 47 loss: 0.41855210523166314\n",
      "Epoch: 48, Batch: 200/782, Loss: 1.790978490114212\n",
      "Epoch: 48, Batch: 400/782, Loss: 1.797570892572403\n",
      "Epoch: 48, Batch: 600/782, Loss: 1.8027039986848832\n",
      "Epoch 48 loss: 0.41456936677093703\n",
      "Epoch: 49, Batch: 200/782, Loss: 1.788369629383087\n",
      "Epoch: 49, Batch: 400/782, Loss: 1.7931565099954605\n",
      "Epoch: 49, Batch: 600/782, Loss: 1.7949798488616944\n",
      "Epoch 49 loss: 0.41884173029828864\n",
      "Epoch: 50, Batch: 200/782, Loss: 1.7764247220754623\n",
      "Epoch: 50, Batch: 400/782, Loss: 1.7827473628520965\n",
      "Epoch: 50, Batch: 600/782, Loss: 1.7864512902498246\n",
      "Epoch 50 loss: 0.4171676719585038\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 62 %\n"
     ]
    }
   ],
   "source": [
    "# MobileNet 模型\n",
    "net = mobilenet_v2(pretrained=False)\n",
    "net.classifier[1] = nn.Linear(net.classifier[1].in_features, 10)\n",
    "net.to(device)\n",
    "print(\"start\")\n",
    "\n",
    "# 训练模型\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.003, momentum=0.9)\n",
    "\n",
    "for epoch in range(50):  # 遍历数据集多次\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #labels = labels.numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        # 添加噪声\n",
    "        noisy_labels = add_label_noise(labels, noise_type='symmetric', noise_rate=0.4)\n",
    "        noisy_labels = torch.from_numpy(noisy_labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, noisy_labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "         # 打印当前进度\n",
    "        if i % 200 == 199:    # 每 200 批次打印一次\n",
    "            print(f'Epoch: {epoch + 1}, Batch: {i + 1}/{len(trainloader)}, Loss: {running_loss / 200}')\n",
    "            running_loss = 0.0\n",
    "            \n",
    "\n",
    "    print(f'Epoch {epoch + 1} loss: {running_loss / len(trainloader)}')\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# 评估模型\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
